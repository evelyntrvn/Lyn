<head>
</head>

<body>
  <div id="editor"></div>
  <canvas id="gl"></canvas>
</body>

<script src="https://unpkg.com/codemirror@5.65.9/lib/codemirror.js"></script>
<link rel="stylesheet" href="https://unpkg.com/codemirror@5.65.9/lib/codemirror.css"/>
<link rel="stylesheet" href="style.css" />

<script src="https://cdn.jsdelivr.net/npm/tweakpane@3.0.7/dist/tweakpane.min.js"></script>
<!-- vertex shader, as simple as possible -->
<script id="vertex" type="x-shader/x-vertex">
  attribute vec2 a_position;

  void main() {
    gl_Position = vec4( a_position, 0, 1 );
  }
</script>

<script id="simulation" type="x-shader/x-fragment">
  #ifdef GL_ES
      precision mediump float;
  #endif

  uniform float time;
  uniform vec2 resolution;
  uniform float dA;
  uniform float dB;
  uniform float feed;
  uniform float kill;
  uniform float size;
  uniform float audioData;

  // simulation texture state, swapped each frame
  uniform sampler2D state;

  // look up individual cell values
  float getA(int x, int y) {
      return float(
        texture2D( state, ( gl_FragCoord.xy + vec2(x, y) ) / resolution ).r
      );
    }

  float getB(int x, int y) {
      return float(
        texture2D( state, ( gl_FragCoord.xy + vec2(x, y) ) / resolution ).g
      );
  }

  float laplaceA(){
      float sumA = 0.;

      sumA += getA(0,0) * -1.;
      sumA += getA(-1,0) * 0.2;
      sumA += getA(1,0) * 0.2;
      sumA += getA(0,-1) * 0.2;
      sumA += getA(0,1) * 0.2;
      sumA += getA(-1,-1) * 0.05;
      sumA += getA(1,1) * 0.05;
      sumA += getA(-1,1) * 0.05;
      sumA += getA(1,-1) * 0.05;

      return sumA;
  }

  float laplaceB(){
      float sumB = 0.;

      sumB += getB(0,0) * -1.;
      sumB += getB(-1,0) * 0.2;
      sumB += getB(1,0) * 0.2;
      sumB += getB(0,-1) * 0.2;
      sumB += getB(0,1) * 0.2;
      sumB += getB(-1,-1) * 0.05;
      sumB += getB(1,1) * 0.05;
      sumB += getB(-1,1) * 0.05;
      sumB += getB(1,-1) * 0.05;

      return sumB;
  }

  float random (vec2 st) {
    return fract(sin(dot(st.xy, vec2(12.9898,78.233)))* 43758.5453123);
  }
  float shine (in vec2 pos){
    vec2 i = floor(pos);
    vec2 f = fract(pos);

    float a = random (i);
    float b = random (i + vec2(1., 0.));
    float c = random (i + vec2(0., 1.));
    float d = random (i + vec2(1., 1.));

    vec2 u = smoothstep(0.,1.,f);

    return mix(a, b, u.x) +
            (c - a) * u.y * (1. - u.x) +
            (d - b) * u.x * u.y;
  }

  void main() {
      vec2 pos = gl_FragCoord.xy / resolution;
      float a = getA(0,0);
      float b = getB(0,0);
      float c = audioData/255.;

      float nextA = a +
                  (dA * laplaceA() * size
                  - a * b * b
                  + feed * ( 1. - a )) ;

      float nextB = b +
                  (dB * laplaceB() * size
                  + a * b * b
                  - (kill + feed) * b);

      vec3 next = vec3(nextA, nextB, c);
      float f = shine(vec2( pos * .05));
      vec3 result = next + vec3(f);

      gl_FragColor = vec4(result, 1.);
  }
</script>

<!-- render to screen shader -->
<script id="render" type="x-shader/x-fragment">
  #ifdef GL_ES
  precision mediump float;
  #endif

  uniform sampler2D uSampler;
  uniform vec2 resolution;

  void main() {
    gl_FragColor = vec4( texture2D( uSampler, gl_FragCoord.xy / resolution ).rgb, 1. );
  }
</script>

<script type="text/javascript">
  let gl,
    framebuffer,
    simulationProgram,
    drawProgram,
    uTime,
    uSimulationState,
    textureBack,
    textureFront,
    dimensions = { width: null, height: null },
    dA,
    dB,
    feed,
    k,
    size,
    audio,
    audioData,
    bufferLength,
    analyser,
    audioContext,
    audioElement,
    playing = false,
    mic = false;

  window.onload = function () {
    navigator.mediaDevices
      .getUserMedia({ audio: true, video: false })
      .then(function (stream) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        audioElement = document.querySelector("audio");
        //const track = audioContext.createMediaStreamSource(stream);
        const track = audioContext.createMediaElementSource(audioElement);

        analyser = audioContext.createAnalyser();
        analyser.fftSize = 256;
        bufferLength = analyser.frequencyBinCount;
        audio = new Uint8Array(bufferLength);

        console.log(bufferLength);

        track.connect(analyser);
        analyser.connect(audioContext.destination);

        analyser.getByteFrequencyData(audio);
        console.log(audio);
        //getAudioData(audio)
        mic = true;

        audioElement.addEventListener(
          "ended",
          () => {
            playButton.dataset.playing = "false";
          },
          false
        );
      });

    const pane = new Tweakpane.Pane();
    const PARAMS = {
      song: "Marble Soda",
      dA: 1,
      dB: 0.1,
      feed: 0.055,
      size: 0.5,
    };

    const playMusic = pane.addButton({ title: "Play/Pause Music" });

    const song = pane.addInput(PARAMS, "song", {
      options: {
        "Marble Soda": "audio/marbleSoda.mp3",
        Lacrimosa: "audio/lacrimosa.mp3",
        "Burnt Rice": "audio/burntRice.mp3",
      },
    });
    const dAInput = pane.addInput(PARAMS, "dA", { min: 0, max: 1 });
    const dBInput = pane.addInput(PARAMS, "dB", { min: 0, max: 1 });
    const feedInput = pane.addInput(PARAMS, "feed", { min: 0, max: 0.1 });
    const sizeInput = pane.addInput(PARAMS, "size", { min: 0, max: 1 });

    dAInput.on("change", function (ev) {
      dA = ev.value;
      // console.log("da= " + ev.value)
    });
    dBInput.on("change", function (ev) {
      dB = ev.value;
    });
    feedInput.on("change", function (ev) {
      feed = ev.value;
    });
    sizeInput.on("change", function (ev) {
      size = ev.value;
    });
    song.on("change", function (ev) {
      audioElement.src = ev.value;
    });

    playMusic.on(
      "click",
      function () {
        // play or pause track depending on state
        if (playing === false) {
          audioElement.play();
          playing = true;
        } else if (playing === true) {
          audioElement.pause();
          playing = false;
        }
      },
      false
    );

    dA = PARAMS["dA"];
    dB = PARAMS["dB"];
    feed = PARAMS["feed"];
    size = PARAMS["size"];
    kill = 0;

    const canvas = document.getElementById("gl");
    gl = canvas.getContext("webgl");
    canvas.width = dimensions.width = window.innerWidth;
    canvas.height = dimensions.height = window.innerHeight;

    // define drawing area of webgl canvas. bottom corner, width / height
    // XXX can't remember why we need the *2!
    gl.viewport(0, 0, gl.drawingBufferWidth, gl.drawingBufferHeight);

    makeBuffer();
    makeShaders();
    makeTextures();
    setInitialState();

    const cm = CodeMirror(document.getElementById("editor"), {
      value: "function myScript(){return 100;}\n",
      mode: "javascript",
      lineNumbers: true
    });
    

    cm.setOption("extraKeys", {
      "Ctrl-Enter": function (cm) {
        console.log(cm.getValue());
        eval;
      },
    });
    /* run function, parse, then feed output to eval */
  };

  function poke(x, y, valA, valB, texture) {
    gl.bindTexture(gl.TEXTURE_2D, texture);
    gl.texSubImage2D(
      gl.TEXTURE_2D,
      0,
      // x offset, y offset, width, height
      x,
      y,
      1,
      1,
      gl.RGBA,
      gl.UNSIGNED_BYTE,
      // is supposed to be a typed array
      new Uint8Array([valA, valB, 0, 1])
    );
  }

  function setInitialState() {
    var width = dimensions.width,
      height = dimensions.height;

    for (i = 0; i < width; i++) {
      for (j = 0; j < height; j++) {
        if (
          i > width / 3 &&
          j > height / 3 &&
          i < width - width / 3 &&
          j < height - height / 3
        ) {
          poke(i, j, 0, 255, textureBack);
        } else {
          poke(i, j, 255, 0, textureBack);
        }
      }
    }
    //console.log("poked")
    //console.log(0.065 + (0 - 0) * (0.07 - 0.065) / (255 - 0))
  }

  function makeBuffer() {
    // create a buffer object to store vertices
    const buffer = gl.createBuffer();

    // point buffer at graphic context's ARRAY_BUFFER
    gl.bindBuffer(gl.ARRAY_BUFFER, buffer);

    const triangles = new Float32Array([
      -1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1,
    ]);

    // initialize memory for buffer and populate it. Give
    // open gl hint contents will not change dynamically.
    gl.bufferData(gl.ARRAY_BUFFER, triangles, gl.STATIC_DRAW);
  }

  function makeShaders() {
    // create vertex shader
    let shaderScript = document.getElementById("vertex");
    let shaderSource = shaderScript.text;
    const vertexShader = gl.createShader(gl.VERTEX_SHADER);
    gl.shaderSource(vertexShader, shaderSource);
    gl.compileShader(vertexShader);

    // create fragment shader
    shaderScript = document.getElementById("render");
    shaderSource = shaderScript.text;
    const drawFragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
    gl.shaderSource(drawFragmentShader, shaderSource);
    gl.compileShader(drawFragmentShader);
    console.log(gl.getShaderInfoLog(drawFragmentShader));

    // create render program that draws to screen
    drawProgram = gl.createProgram();
    gl.attachShader(drawProgram, vertexShader);
    gl.attachShader(drawProgram, drawFragmentShader);

    gl.linkProgram(drawProgram);
    gl.useProgram(drawProgram);

    uRes = gl.getUniformLocation(drawProgram, "resolution");
    gl.uniform2f(uRes, gl.drawingBufferWidth, gl.drawingBufferHeight);

    // get position attribute location in shader
    let position = gl.getAttribLocation(drawProgram, "a_position");
    // enable the attribute
    gl.enableVertexAttribArray(position);
    // this will point to the vertices in the last bound array buffer.
    // In this example, we only use one array buffer, where we're storing
    // our vertices
    gl.vertexAttribPointer(position, 2, gl.FLOAT, false, 0, 0);

    shaderScript = document.getElementById("simulation");
    shaderSource = shaderScript.text;
    const simulationFragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
    gl.shaderSource(simulationFragmentShader, shaderSource);
    gl.compileShader(simulationFragmentShader);
    console.log(gl.getShaderInfoLog(simulationFragmentShader));

    // create simulation program
    simulationProgram = gl.createProgram();
    gl.attachShader(simulationProgram, vertexShader);
    gl.attachShader(simulationProgram, simulationFragmentShader);

    gl.linkProgram(simulationProgram);
    gl.useProgram(simulationProgram);

    uRes = gl.getUniformLocation(simulationProgram, "resolution");
    gl.uniform2f(uRes, gl.drawingBufferWidth, gl.drawingBufferHeight);

    // find a pointer to the uniform "time" in our fragment shader
    uTime = gl.getUniformLocation(simulationProgram, "time");
    uDA = gl.getUniformLocation(simulationProgram, "dA");
    uDB = gl.getUniformLocation(simulationProgram, "dB");
    uFeed = gl.getUniformLocation(simulationProgram, "feed");
    uKill = gl.getUniformLocation(simulationProgram, "kill");
    uSize = gl.getUniformLocation(simulationProgram, "size");

    uAudio = gl.getUniformLocation(simulationProgram, "audioData");

    //uSimulationState = gl.getUniformLocation( simulationProgram, 'state' )

    position = gl.getAttribLocation(simulationProgram, "a_position");
    gl.enableVertexAttribArray(simulationProgram);
    gl.vertexAttribPointer(position, 2, gl.FLOAT, false, 0, 0);
  }

  function makeTextures() {
    gl.getExtension("EXT_color_buffer_float");
    textureBack = gl.createTexture();
    gl.bindTexture(gl.TEXTURE_2D, textureBack);

    // these two lines are needed for non-power-of-2 textures
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);

    // how to map when texture element is less than one pixel
    // use gl.NEAREST to avoid linear interpolation
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
    // how to map when texture element is more than one pixel
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);

    // specify texture format, see https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/texImage2D
    gl.texImage2D(
      gl.TEXTURE_2D,
      0,
      gl.RGBA,
      dimensions.width,
      dimensions.height,
      0,
      gl.RGBA,
      gl.UNSIGNED_BYTE,
      null
    );

    textureFront = gl.createTexture();
    gl.bindTexture(gl.TEXTURE_2D, textureFront);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
    gl.texImage2D(
      gl.TEXTURE_2D,
      0,
      gl.RGBA,
      dimensions.width,
      dimensions.height,
      0,
      gl.RGBA,
      gl.UNSIGNED_BYTE,
      null
    );

    // Create a framebuffer and attach the texture.
    framebuffer = gl.createFramebuffer();

    render();
  }

  // keep track of time via incremental frame counter
  let time = 0;
  function render() {
    // schedules render to be called the next time the video card requests
    // a frame of video
    window.requestAnimationFrame(render);

    // use our simulation shader
    gl.useProgram(simulationProgram);

    if (mic === true) {
      analyser.getByteFrequencyData(audio);
      let sum = 0;
      for (var i = 0; i < bufferLength; i++) {
        sum += audio[i];
      }
      audioData = sum / bufferLength;
      kill = getK(audioData);
      //console.log(kill)
    }

    // update time on CPU and GPU
    time++;
    gl.uniform1f(uTime, time);
    gl.uniform1f(uDA, dA);
    gl.uniform1f(uDB, dB);
    gl.uniform1f(uFeed, feed);
    gl.uniform1f(uKill, kill);
    gl.uniform1f(uSize, size);
    gl.uniform1f(uAudio, audioData);

    gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);
    // use the framebuffer to write to our texFront texture
    gl.framebufferTexture2D(
      gl.FRAMEBUFFER,
      gl.COLOR_ATTACHMENT0,
      gl.TEXTURE_2D,
      textureFront,
      0
    );
    // set viewport to be the size of our state (game of life simulation)
    // here, this represents the size that will be drawn onto our texture
    gl.viewport(0, 0, dimensions.width, dimensions.height);

    // in our shaders, read from texBack, which is where we poked to
    gl.activeTexture(gl.TEXTURE0);
    gl.bindTexture(gl.TEXTURE_2D, textureBack);
    gl.uniform1i(uSimulationState, 0);
    // run shader
    gl.drawArrays(gl.TRIANGLES, 0, 6);

    // swap our front and back textures
    let tmp = textureFront;
    textureFront = textureBack;
    textureBack = tmp;

    // use the default framebuffer object by passing null
    gl.bindFramebuffer(gl.FRAMEBUFFER, null);
    // set our viewport to be the size of our canvas
    // so that it will fill it entirely
    gl.viewport(0, 0, dimensions.width, dimensions.height);
    // select the texture we would like to draw to the screen.
    // note that webgl does not allow you to write to / read from the
    // same texture in a single render pass. Because of the swap, we're
    // displaying the state of our simulation ****before**** this render pass (frame)
    gl.bindTexture(gl.TEXTURE_2D, textureFront);
    // use our drawing (copy) shader
    gl.useProgram(drawProgram);
    // put simulation on screen
    gl.drawArrays(gl.TRIANGLES, 0, 6);
  }

  function map(value, min1, max1, min2, max2) {
    return min2 + ((value - min1) * (max2 - min2)) / (max1 - min1);
  }

  function getK(c) {
    return map(c, 0, 255, 0.045, 0.1);
  }
</script>
